# MMDFD- A Multimodal Custom Dataset for Deepfake Detection
![Screenshot (154)](https://github.com/abdullaImzan/CustomDB/assets/137156878/0cafc806-0b31-47b9-9b15-fbf32a6b3d84)

### Overview
The MMDFD dataset is a novel multi-modal dataset created to improve deepfake detection methods by including audio, video, and textual deepfakes simultaneously. It addresses the need for diverse and unbiased datasets to combat 
the growing threat of deepfake misuse, providing a valuable resource for developing accurate detection algorithms. See [paper](https://dl.acm.org/doi/10.1145/3607947.3608013) for details.

Please cite our paper in your publications if MMFD is used in your research:
```
@inproceedings{10.1145/3607947.3608013,
author = {S, ASHA and P, VINOD and Menon, Varun G},
title = {MMDFD- A Multimodal Custom Dataset for Deepfake Detection},
year = {2023},
isbn = {9798400700224},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3607947.3608013},
doi = {10.1145/3607947.3608013},
abstract = {A multi-modal deepfake dataset is relevant in addressing the growing concern of deepfake misuse, which poses a significant security and privacy threat. Deepfakes are becoming increasingly sophisticated, and their potential to deceive individuals and organizations is a significant issue. The ability to generate synthesized human voices using deep learning models and inserting fake subtitles has added to this problem, making it more challenging to detect deepfakes accurately. A superior quality dataset is essential to developing a competent deepfake detector. However, existing datasets are limited and often biased, making it difficult to detect deepfakes accurately. A multi-modal deepfake dataset, such as the proposed multi-modal Audio-Video-Text Deepfake dataset (MMDFD) addresses this gap by providing a more realistic and unbiased dataset. Such a dataset helps develop more accurate and effective deepfake detection methods, which can detect audio, video, and textual deepfakes simultaneously. The proposed dataset is more reflective of situations in the real world since it contains actual YouTube recordings of celebrities from four different racial origins. This helps to avoid the creation of deepfake detectors that are biased toward certain racial or ethnic groups. Overall, a multi-modal deepfake dataset is essential in addressing the growing concerns of deepfake misuse and developing effective detection methods that can detect deepfakes accurately, regardless of the medium.},
booktitle = {Proceedings of the 2023 Fifteenth International Conference on Contemporary Computing},
pages = {322–327},
numpages = {6},
keywords = {Deep neural networks, Deepfake Dataset, Multimodal, Subtitle Deepfakes},
location = {, Noida, India, },
series = {IC3-2023}
}

```
### Dataset Contents
![Screenshot (165)](https://github.com/abdullaImzan/CustomDB/assets/137156878/3e47235f-a514-4c81-85a9-56ea96bbf7dd)

### Comparison with Other Datasets
![Screenshot (164)](https://github.com/abdullaImzan/CustomDB/assets/137156878/e38274a5-1dcf-498f-b124-f65f5f1bccb6)

### References
[1] Joon Son Chung, Arsha Nagrani, and Andrew Zisserman. 2018. Voxceleb2: Deep
speaker recognition. arXiv preprint arXiv:1806.05622 (2018).
[2] AI Communis. 2021. AurisaiAI Transcribe audio to text and add subtitles to videos
instantly. https://aurisai.io/
[3] Brian Dolhansky, Russ Howes, Ben Pflaum, Nicole Baram, and Cristian Canton
Ferrer. 2019. The deepfake detection challenge (dfdc) preview dataset. arXiv
preprint arXiv:1910.08854 (2019).
[4] Nick Dufour and Andrew Gully. [n. d.]. Contributing data to deepfake detection
research(2019).
[5] Shreyan Ganguly, Sk Mohiuddin, Samir Malakar, Erik Cuevas, and Ram Sarkar.
2022. Visual attention-based deepfake video forgery detection. Pattern Analysis
and Applications (2022), 1–12.
[6] Brian Hosler, Davide Salvi, Anthony Murray, Fabio Antonacci, Paolo Bestagini,
Stefano Tubaro, and Matthew C Stamm. 2021. Do Deepfakes Feel Emotions? A
Semantic Approach to Detecting Deepfakes via Emotional Inconsistencies. In
Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition.
1013–1022.
[7] Ye Jia, Yu Zhang, Ron J Weiss, Quan Wang, Jonathan Shen, Fei Ren, Zhifeng Chen,
Patrick Nguyen, Ruoming Pang, Ignacio Lopez Moreno, et al. 2018. Transfer
learning from speaker verification to multispeaker text-to-speech synthesis. arXiv
preprint arXiv:1806.04558 (2018).
[8] Hasam Khalid, Minha Kim, Shahroz Tariq, and Simon S Woo. 2021. Evaluation of
an Audio-Video Multimodal Deepfake Dataset using Unimodal and Multimodal
Detectors. In Proceedings of the 1st Workshop on Synthetic Multimedia-Audiovisual
Deepfake Generation and Detection. 7–15.
[9] Hasam Khalid, Shahroz Tariq, Minha Kim, and Simon S Woo. 2021. FakeAVCeleb:
a novel audio-video multimodal deepfake dataset. arXiv preprint arXiv:2108.05080
(2021).
[10] Pavel Korshunov and Sébastien Marcel. 2018. Deepfakes: a new threat to face
recognition? assessment and detection. arXiv preprint arXiv:1812.08685 (2018).
[11] John K Lewis, Imad Eddine Toubal, Helen Chen, Vishal Sandesera, Michael Lomnitz, Zigfried Hampel-Arias, Calyam Prasad, and Kannappan Palaniappan. 2020.
Deepfake Video Detection Based on Spatial, Spectral, and Temporal Inconsistencies Using Multimodal Deep Learning. In 2020 IEEE Applied Imagery Pattern
Recognition Workshop (AIPR). IEEE, 1–9.
[12] Yuezun Li and Siwei Lyu. 2018. Exposing deepfake videos by detecting face
warping artifacts. arXiv preprint arXiv:1811.00656 (2018).
[13] Yuezun Li, Xin Yang, Pu Sun, Honggang Qi, and Siwei Lyu. 2020. Celeb-df:
A large-scale challenging dataset for deepfake forensics. In Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern Recognition. 3207–3216.
[14] Michael Lomnitz, Zigfried Hampel-Arias, Vishal Sandesara, and Simon Hu. 2020.
Multimodal Approach for DeepFake Detection. In 2020 IEEE Applied Imagery
Pattern Recognition Workshop (AIPR). IEEE, 1–9.
[15] Momina Masood, Marriam Nawaz, Khalid Mahmood Malik, Ali Javed, and Aun
Irtaza. 2021. Deepfakes Generation and Detection: State-of-the-art, open challenges, countermeasures, and way forward. arXiv preprint arXiv:2103.00484
(2021).
[16] Trisha Mittal, Uttaran Bhattacharya, Rohan Chandra, Aniket Bera, and Dinesh
Manocha. 2020. Emotions don’t lie: A deepfake detection method using audiovisual affective cues. arXiv preprint arXiv:2003.06711 3 (2020).
[17] KR Prajwal, Rudrabha Mukhopadhyay, Vinay P Namboodiri, and CV Jawahar.
2020. A lip sync expert is all you need for speech to lip generation in the wild. In
Proceedings of the 28th ACM International Conference on Multimedia. 484–492.
[18] Andreas Rossler, Davide Cozzolino, Luisa Verdoliva, Christian Riess, Justus Thies,
and Matthias Nießner. 2019. Faceforensics++: Learning to detect manipulated
facial images. In Proceedings of the IEEE/CVF International Conference on Computer
Vision. 1–11.
[19] Conrad Sanderson. 2002. The vidtimit database. Technical Report. IDIAP.
[20] Duha A Sultan and Laheeb M Ibrahim. 2022. A Comprehensive Survey on
Deepfake Detection Techniques. International Journal of Intelligent Systems and
Applications in Engineering 10, 3s (2022), 189–202.
[21] Supasorn Suwajanakorn, Steven M Seitz, and Ira Kemelmacher-Shlizerman. 2017.
Synthesizing obama: learning lip sync from audio. ACM Transactions on Graphics
(ToG) 36, 4 (2017), 1–13.
[22] Youtube. [n. d.]. BBC has wrong subtitles for Trump’s Inauguration. https:
//www.youtube.com/shorts/4jtzzAQgswo
[23] Yipin Zhou and Ser-Nam Lim. 2021. Joint audio-visual deepfake detection. In
Proceedings of the IEEE/CVF International Conference on Computer Vision. 14800–
14809.

